{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium.webdriver as webdriver\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#sys libraries\n",
    "from time import sleep\n",
    "import requests\n",
    "import random\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import getpass\n",
    "import string\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import data viz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nltk and wordcloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows' , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting from user input\n",
    "# try:\n",
    "#     username = input('Enter your Username ')\n",
    "#     password = getpass.getpass('Enter your password ')\n",
    "#     desired_job = input('Searched job query: ')\n",
    "#     desired_location = input('Location: ')\n",
    "# except Exception as error: \n",
    "#     print('ERROR', error) \n",
    "    \n",
    "    \n",
    "username = 'behdad.k7@gmail.com'\n",
    "password = '1988behrooz10973'\n",
    "desired_keyword = 'data scientist in united kingdom'\n",
    "desired_location = 'United Kingdom'\n",
    "\n",
    "csv_file = str.strip(desired_keyword)\n",
    "file_name = csv_file + \"_\" + str(desired_location) +'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path= \"geckodriver.exe\")\n",
    "\n",
    "profile = webdriver.FirefoxProfile()\n",
    "profile.set_preference(\"browser.cache.disk.enable\", False)\n",
    "profile.set_preference(\"browser.cache.memory.enable\", False)\n",
    "profile.set_preference(\"browser.cache.offline.enable\", False)\n",
    "profile.set_preference(\"network.http.use-cache\", False)\n",
    "profile.update_preferences()\n",
    "\n",
    "driver.get(url='https://www.linkedin.com/')\n",
    "sleep(2)\n",
    "\n",
    "# Find the sign in botthon\n",
    "sign_in = driver.find_element(by='link text', value='Sign in')\n",
    "sign_in.click()\n",
    "sleep(5)\n",
    "\n",
    "# We find the input section and enter our user information.\n",
    "email_entry = driver.find_element(by='css selector', value='#username')\n",
    "password_entry = driver.find_element(by='css selector', value='#password')\n",
    "\n",
    "# For every letter in our email, we will set a random time between keystrokes\n",
    "for letter in username:\n",
    "    sleep(random.uniform(.1, .4))\n",
    "    email_entry.send_keys(letter)\n",
    "\n",
    "# We expect a random time between 0.1 and 0.4 sec for each letter of our password.\n",
    "for letter in password:\n",
    "    sleep(random.uniform(.1, .4))\n",
    "    password_entry.send_keys(letter)\n",
    "\n",
    "# We press enter\n",
    "password_entry.send_keys(Keys.RETURN)\n",
    "sleep(10)\n",
    "\n",
    "# click on typehead search bar\n",
    "search_bar = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@placeholder='Search']\")))\n",
    "search_bar.click()\n",
    "\n",
    "# Enter the job search term and press enter\n",
    "for letter in desired_keyword:\n",
    "    sleep(random.uniform(.1, .4))\n",
    "    search_bar.send_keys(letter)\n",
    "search_bar.send_keys(Keys.RETURN)\n",
    "sleep(3)\n",
    "\n",
    "\n",
    "# Find and Click on just people button\n",
    "just_people_btn = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[@aria-label='View only People results']\")))\n",
    "just_people_btn.click()\n",
    "sleep(2)\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "current_url = 'url_placeholder' # this is a placeholder for the URL check\n",
    "\n",
    "# Create empty dataframe\n",
    "df = pd.DataFrame(columns = ['name', 'job_title', 'current_company', 'university',\n",
    "                             'degree','location', 'about', 'skills','profile_url'])\n",
    "\n",
    "# Go through pages and download data\n",
    "current_url = driver.current_url\n",
    "while True:\n",
    "    # Check to see if url is the 100th page in search\n",
    "    if current_url.find('page=100') != -1:\n",
    "        break\n",
    "    # Check to see if this url has been scraped before; break loop if it has\n",
    "    previous_url = current_url\n",
    "    current_url = driver.current_url\n",
    "    if current_url == previous_url:\n",
    "        break\n",
    "\n",
    "    driver.get(present_url)\n",
    "    sleep(10)\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(1)\n",
    "    \n",
    "    links = driver.find_elements_by_xpath('//div[contains(@class, \"search-result__info\")]//a[@href]')\n",
    "    profiles_link = set()\n",
    "    for link in links:\n",
    "        link_add=link.get_attribute('href')\n",
    "        print(link_add)\n",
    "        if link_add.startswith('https://www.linkedin.com/in/'):\n",
    "            profiles_link.add(link_add)\n",
    "            \n",
    "    for profile in profiles_link:\n",
    "        try:\n",
    "            driver.get(profile)\n",
    "            sleep(5)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # -------------Scrap here----------------\n",
    "            \n",
    "        print('---------------------------')\n",
    "        print('scraping ...' , profile , '\\n')\n",
    "        sleep(3)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(.75)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(.75)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(.75)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(.75)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(1)\n",
    "        \n",
    "        page = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        \n",
    "        ''' 1)Name'''\n",
    "        try:\n",
    "            name = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//li[contains(@class, \"inline t-24 t-black t-normal break-words\")]')))\n",
    "            name = name.text\n",
    "            if name:\n",
    "                name = name.strip()\n",
    "        except:\n",
    "            name = np.nan\n",
    "                \n",
    "        print('name:\\n',name , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 2)job_title'''\n",
    "        try:\n",
    "            job_title = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//h2[contains(@class, \"mt1 t-18 t-black t-normal\")]')))\n",
    "            job_title = job_title.text\n",
    "            if job_title:\n",
    "                job_title = job_title.strip()\n",
    "        except:\n",
    "            job_title = np.nan\n",
    "                \n",
    "        print('job_title:\\n',job_title , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 3)current_company'''\n",
    "        try:\n",
    "            current_company = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//ul[contains(@class, \"pv-top-card--experience-list\")]/li[1]')))\n",
    "            current_company = current_company.text\n",
    "            if current_company:\n",
    "                current_company = current_company.strip()\n",
    "        except:\n",
    "            current_company = np.nan\n",
    "                \n",
    "        print('current_company:\\n',current_company , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 4)university'''\n",
    "        try:\n",
    "            university = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//ul[contains(@class, \"pv-top-card--experience-list\")]/li[2]')))\n",
    "            if university =='':\n",
    "                degree = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((\n",
    "                        By.XPATH,'//section[contains(@class, \"pv-profile-section education-section ember-view\")]')))\n",
    "            degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//li[1]//div[contains(@class,\"pv-entity__degree-info\")]')))\n",
    "            degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//h3[contains(@class,\"pv-entity__school-name t-16 t-black t-bold\")]')))\n",
    "            \n",
    "            university = university.text\n",
    "            if university:\n",
    "                university = university.strip()\n",
    "        except:\n",
    "            university = np.nan\n",
    "                \n",
    "\n",
    "        print('university:\\n',university , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        \n",
    "        ''' 5)degree'''\n",
    "        try:\n",
    "            degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//section[contains(@class, \"pv-profile-section education-section ember-view\")]')))\n",
    "            degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//li[1]//div[contains(@class,\"pv-entity__degree-info\")]')))\n",
    "            degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//span[contains(@class,\"pv-entity__comma-item\")]')))\n",
    "            degree = degree.text\n",
    "            if degree=='':\n",
    "                degree = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//p[contains(@class,\"pv-entity__degree-name\")]')))\n",
    "                degree = degree.text\n",
    "            \n",
    "            if degree:\n",
    "                degree = degree.strip()\n",
    "        except:\n",
    "            degree = np.nan\n",
    "                \n",
    "        print('degree:\\n',degree , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 6)location'''\n",
    "        try:\n",
    "            location = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//ul[contains(@class, \"pv-top-card--list pv-top-card--list-bullet mt1\")]/li[1]')))\n",
    "            location = location.text\n",
    "            if location:\n",
    "                location = location.strip()\n",
    "        except:\n",
    "            location = np.nan\n",
    "        \n",
    "        print('location:\\n',location , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 7)about'''\n",
    "        try:\n",
    "            about = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//section[contains(@class, \"artdeco-container-card pv-profile-section pv-about-section ember-view\")]//a[contains(@class,\"lt-line-clamp__more\")]'))).click()\n",
    "            about = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,'//p[contains(@class,\"pv-about__summary-text mt4 t-14 ember-view\")]')))      \n",
    "            about = about.text\n",
    "            if about:\n",
    "                about = about.strip()\n",
    "        except:\n",
    "            about = np.nan\n",
    "             \n",
    "        print('about:\\n',about , '\\n')\n",
    "        sleep(0.5)\n",
    "        \n",
    "        ''' 8)skills'''\n",
    "        \n",
    "        try:      \n",
    "            print(\"skills search ... \")\n",
    "            skills = page.find_all('span', class_ = \"pv-skill-category-entity__name-text\")\n",
    "            \n",
    "            #Put scraped data into a ski_df\n",
    "            arraylen3 = len(page.find_all('span', class_ = \"pv-skill-category-entity__name-text\"))\n",
    "        \n",
    "            profile = pro\n",
    "            skills = list(map(lambda x: x.text.strip(), skills))[0:arraylen3]\n",
    "        except:\n",
    "            skills = np.nan\n",
    "                \n",
    "        print('skills:  ',skills , '\\n')\n",
    "        sleep(0.5)\n",
    "\n",
    "\n",
    "        \n",
    "        temp = pd.DataFrame({'name': name, 'job_title': job_title, 'current_company': current_company,\n",
    "                             'university': university, 'degree': degree, 'location':location, \n",
    "                             'about':about,'skills': skills, 'profile_url': profile})\n",
    "\n",
    "        # Filter out members who do not provide information\n",
    "        temp = temp[temp['name'] != 'LinkedIn Member']\n",
    "\n",
    "        # Append new data to df\n",
    "        df = df.append(temp)\n",
    "\n",
    "    # Find next button and hit next\n",
    "    nextt = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//button[contains(@class,'artdeco-pagination__button artdeco-pagination__button--next artdeco-button artdeco-button--muted artdeco-button--icon-right artdeco-button--1 artdeco-button--tertiary')]\")))\n",
    "    sleep(2)\n",
    "    nextt.click()\n",
    "    sleep(2)\n",
    "\n",
    "# Reset dataframe index\n",
    "df.reset_index()\n",
    "\n",
    "# Export results\n",
    "df.to_csv(\"UK_data_scientist.csv\", index = False)\n",
    "\n",
    "# Close Selenium\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
